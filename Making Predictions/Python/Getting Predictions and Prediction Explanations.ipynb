{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Predictions and Prediction Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope\n",
    "\n",
    "The scope of this notebook is to provide instructions on how to get predictions and prediction explanations out of a trained model using the Python API.\n",
    "\n",
    "### Background\n",
    "\n",
    "The main ways you can get predictions out of DataRobot using Python would be the modeling API and the prediction API.\n",
    "\n",
    "**Modeling API**: You can use the modelling API if you use Python or R and there are multiple ways you can interact with it.\n",
    "\n",
    "**Prediction API**: Any project can be called with the Prediction API if you have prediction servers. This is a simple REST API. Click on a model in the UI, then \"Deploy Model\" and \"Activate now\". You'll have access to a Python code snippet to help you interact with it. You can also deploy the model through the python API.\n",
    "\n",
    "\n",
    "For the purposes of this tutorial, we will focus on the Modeling API.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Python version 3.7.3\n",
    "-  DataRobot API version 2.19.0. \n",
    "Small adjustments might be needed depending on the Python version and DataRobot API version you are using.\n",
    "\n",
    "Full documentation of the Python package can be found here:Â https://datarobot-public-api-client.readthedocs-hosted.com/en/\n",
    "\n",
    "It is assumed you already have a DataRobot <code>Project</code> object and a DataRobot <code>Model </code> object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requesting Predictions\n",
    "\n",
    "Before actually requesting predictions, you should upload the dataset you wish to predict via <code>Project.upload_dataset</code>. Previously uploaded datasets can be seen under <code>Project.get_datasets</code>. When uploading the dataset you can provide the path to a local file, a file object, raw file content, a pandas.DataFrame object, or the url to a publicly available dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading prediction dataset\n",
    "dataset_from_path = project.upload_dataset('path/file')\n",
    "\n",
    "#Request predictions\n",
    "predict_job = model.request_predictions(dataset_from_path.id)\n",
    "\n",
    "#Waiting for prediction calculations\n",
    "predictions = predict_job.get_result_when_complete()\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requesting Prediction Explanations\n",
    "In order to create PredictionExplanations for a particular model and dataset, you must first Compute feature impact for the model via <code>dr.Model.get_or_request_feature_impact()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_or_request_feature_impact()\n",
    "\n",
    "pei = dr.PredictionExplanationsInitialization.create(project.id, model.id)\n",
    "\n",
    "#Wait for results of Prediction Explanations\n",
    "pei.get_result_when_complete()\n",
    "\n",
    "pe_job = dr.PredictionExplanations.create(project.id, model.id,  dataset_from_path.id)\n",
    "\n",
    "#Waiting for Job to Complete\n",
    "pe = pe_job.get_result_when_complete()\n",
    "\n",
    "df_pe = pe.get_all_as_dataframe()\n",
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Projects Caveats\n",
    "Prediction datasets are uploaded as normal predictions. However, when uploading a prediction dataset, a new parameter forecastPoint can be specified. The forecast point of a prediction dataset identifies the point in time relative which predictions should be generated, and if one is not specified when uploading a dataset, the server will choose the most recent possible forecast point. The forecast window specified when setting the partitioning options for the project determines how far into the future from the forecast point predictions should be calculated.\n",
    "\n",
    "**Important Note**:\n",
    "When uploading a dataset for Time Series projects scoring, you need to include the actual values from previous dates depending on the feature derivation setup. For example, if feature derivation window is -10 to -1 days and you want to forecast sales for the next 3 days, your dataset would look like this:\n",
    "\n",
    "| date       | sales | Known_in_advance_feature |\n",
    "|------------|-------|--------------------------|\n",
    "| 01/01/2019 | 130   | AAA                      |\n",
    "| 02/01/2019 | 123   | VVV                      |\n",
    "| 03/01/2019 | 412   | BBB                      |\n",
    "| 04/01/2019 | 321   | DDD                      |\n",
    "| 05/01/2019 | 512   | DDD                      |\n",
    "| 06/01/2019 | 623   | VVV                      |\n",
    "| 07/01/2019 | 356   | CCC                      |\n",
    "| 08/01/2019 | 133   | AAA                      |\n",
    "| 09/01/2019 | 356   | CCC                      |\n",
    "| 10/01/2019 | 654   | DDD                      |\n",
    "| 11/01/2019 |       | BBB                      |\n",
    "| 12/01/2019 |       | CCC                      |\n",
    "| 13/01/2019 |       | DDD                      |\n",
    "\n",
    "DataRobot will detect your forecast point as 10/01/2019 and then it will calculate lag features and make predictions for the missing dates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
